{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3o5cXoEGY7i+s8TWK+RS/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeon-Gahui/BAF-Study-2026-winter/blob/main/RAG%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zSImFYZAhy1E"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install cohere faiss-cpu rank_bm25 langchain-community langchain_huggingface\n",
        "\n",
        "# 사용하는 파이썬과 CUDA 버전에 맞는 llama-cpp-python 패키지 설치\n",
        "!pip install https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.16-cu124/llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4LNwOWTHvOv",
        "outputId": "a9ca2e79-7359-4e7e-8c9c-43026457b19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-12 07:33:49--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.11, 3.165.160.12, 3.165.160.59, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/662698108f7573e6a6478546/df220524a4e4a750fe1c325e41f09ff69137f38b52d8831ba22dcbee3cc8ab6d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260212T073349Z&X-Amz-Expires=3600&X-Amz-Signature=96dcc88f0481b0c921cf050255eeb0166fdeadd63269104b66df7ab9f0d2d912&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-q4.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-q4.gguf%22%3B&x-id=GetObject&Expires=1770885229&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc3MDg4NTIyOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjI2OTgxMDhmNzU3M2U2YTY0Nzg1NDYvZGYyMjA1MjRhNGU0YTc1MGZlMWMzMjVlNDFmMDlmZjY5MTM3ZjM4YjUyZDg4MzFiYTIyZGNiZWUzY2M4YWI2ZCoifV19&Signature=rsSsr9rPUDwQWzjaQ3to217kJ0SeqOt4pLpJTXTRmEIzu1GI3kxc87q12QBbo2glu9NsxacR9DIXVwcc5qv4cjaB56GI77ZVKGmU8MrqLopNZVfU9KSd2aB1hB92usAQkoH9Bh3I-fEJucINx5CXq4X0%7ESly3wtWCWjkyiNM76iYxHMNWxLiYQTKaVuO0Aoff5ikuycsvTZNplJODFNhgC6Cp2hZoe4RtorrffnW4ngtKF8My3B9CTfTPD7y3HqrO5Cp4z6T16FTeepc2eEyGCr0B0Bm8-WVkqHKpw%7EIKtJ0BJA4uYvtcTItDsgQwVKBk7if1eNa%7EWw%7EMk-X7KSU7g__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2026-02-12 07:33:49--  https://cas-bridge.xethub.hf.co/xet-bridge-us/662698108f7573e6a6478546/df220524a4e4a750fe1c325e41f09ff69137f38b52d8831ba22dcbee3cc8ab6d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260212T073349Z&X-Amz-Expires=3600&X-Amz-Signature=96dcc88f0481b0c921cf050255eeb0166fdeadd63269104b66df7ab9f0d2d912&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-q4.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-q4.gguf%22%3B&x-id=GetObject&Expires=1770885229&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc3MDg4NTIyOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjI2OTgxMDhmNzU3M2U2YTY0Nzg1NDYvZGYyMjA1MjRhNGU0YTc1MGZlMWMzMjVlNDFmMDlmZjY5MTM3ZjM4YjUyZDg4MzFiYTIyZGNiZWUzY2M4YWI2ZCoifV19&Signature=rsSsr9rPUDwQWzjaQ3to217kJ0SeqOt4pLpJTXTRmEIzu1GI3kxc87q12QBbo2glu9NsxacR9DIXVwcc5qv4cjaB56GI77ZVKGmU8MrqLopNZVfU9KSd2aB1hB92usAQkoH9Bh3I-fEJucINx5CXq4X0%7ESly3wtWCWjkyiNM76iYxHMNWxLiYQTKaVuO0Aoff5ikuycsvTZNplJODFNhgC6Cp2hZoe4RtorrffnW4ngtKF8My3B9CTfTPD7y3HqrO5Cp4z6T16FTeepc2eEyGCr0B0Bm8-WVkqHKpw%7EIKtJ0BJA4uYvtcTItDsgQwVKBk7if1eNa%7EWw%7EMk-X7KSU7g__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.238.217.63, 18.238.217.88, 18.238.217.64, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.238.217.63|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2393231072 (2.2G)\n",
            "Saving to: ‘Phi-3-mini-4k-instruct-q4.gguf’\n",
            "\n",
            "Phi-3-mini-4k-instr 100%[===================>]   2.23G   209MB/s    in 12s     \n",
            "\n",
            "2026-02-12 07:34:01 (183 MB/s) - ‘Phi-3-mini-4k-instruct-q4.gguf’ saved [2393231072/2393231072]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2Qgnc5OHvRQ",
        "outputId": "8416b7a8-e348-4ea6-deb8-83c3f805bfb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "\n",
        "# 런타임 : T4\n",
        "llm = LlamaCpp(\n",
        "    model_path = \"/content/Phi-3-mini-4k-instruct-q4.gguf\",\n",
        "    n_gpu_layers=-1,\n",
        "    max_tokens=500,\n",
        "    n_ctx=4096,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")"
      ]
    }
  ]
}